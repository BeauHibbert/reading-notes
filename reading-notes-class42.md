# Class 42 Reading Notes

I read the article about Google’s Dragonfly project. What stuck out to me the most was how not   only Google but also tech giants like Facebook have employees working on projects that they may not be fully aware are being used in unethical ways. On multiple occasions when the employees have found out that the tech they were working on was being used for, they either quit or petitioned to stop producing the tech. One quote that stuck out to me was “The fact that Google employees succeeded in forcing one of the most powerful companies in the world to put ethics before shareholder value is a remarkable feat in corporate America, and signals why workers need an official voice in strategic decisions.” I think that this is so powerful is because when you start working at a company, you need to realize that what you are creating can have a real impact on the world, and if it can be used negatively, then the workers need to communicate that to the company and hold the company and themselves responsible. A group of workers petitioned Google with a list of demands that basically sum up to being more transparent about the projects that they work on, and I agree that it should be more transparent. Especially when it comes to producing advanced tech like AI.

The second article that I read was the article about the ethical dilemmas of self driving cars. It basically says that right now we can’t program the cars to make ethical decisions because there hasn’t been enough situations in which they have had the time to program that situation into them. This article is from four years ago so I’m sure self driving car tech has gotten a little bit better since then but I do agree with the article that maybe we shouldn’t have one hundred percent self driving cars yet. I’ve seen videos where a self driving car has definitely saved someones life but I’ve also read articles where the self driving car has locked someone in their vehicle and things like that, so I do believe we may not be ready for fully self driving cars yet. I do think that with some more time that self driving cars are going to take over and will be much safer once we as a society figure out how to answer these ethical dilemma problems but until then, I think we should probably only use partially self driving cars. One’s that can sense when you need to brake and brake for you if you are about to get in an accident. 
